{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPI\n",
    "\n",
    "The aim of this work is to identify the clusters containing HPI genes. We blast HPI sequences on a database constituted of one sequence per cluster. We align the different hits with HPI sequence and we record sequence similarity. As we are also looking for gene fragments we make a distinction between the global similarity (proportion of matches between both sequences once aligned) and the cluster similarity (proportion of matches on the proportion of the alignment that starts with the first base of the cluster sequence and that ends with its last base i.e. we remove the gaps at the beginning and the end of the alignment of the cluster sequence).\n",
    "\n",
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIXML       \n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from Bio import AlignIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../Data/Sequences/\"\n",
    "REFSEQ_FOLDER = DATA_FOLDER+\"Clusters reference sequences/\"\n",
    "HPI_FOLDER = DATA_FOLDER+\"HPI sequences/\"\n",
    "HPI_OUTPUTS = \"../Data/HPI outputs/\"\n",
    "\n",
    "CLUSTERS_GAPS_FILE = REFSEQ_FOLDER+\"refseq.fasta\" # Clusters reference sequences (fasta file)\n",
    "CLUSTERS_FILE= REFSEQ_FOLDER+\"clusters.faa\" #  Clusters reference sequences without gaps (fasta file)\n",
    "SINGLETONS_FILE = REFSEQ_FOLDER+\"singletons.fasta\" # Singletons sequences (fasta file)\n",
    "\n",
    "HPI_FILE = HPI_FOLDER+\"HPI_db.fas\" # HPI sequences (fasta file)\n",
    "BLAST_HPI_CLUSTERS = HPI_FOLDER+\"HPI_clusters.xml\" # BLAST output (HPI blasted against clusters database)\n",
    "BLAST_HPI_SINGLETONS = HPI_FOLDER+\"HPI_singletons.xml\" # BLAST output (HPI blasted against singletons database)\n",
    "\n",
    "ANNOTATIONS_CLUSTERS_CSV = HPI_OUTPUTS+\"clusters_hits.csv\"\n",
    "ANNOTATIONS_SINGLETONS_CSV = HPI_OUTPUTS+\"singletons_hits.csv\"\n",
    "ANNOTATIONS_HPI_CSV = HPI_OUTPUTS+\"HPI_hits.csv\"\n",
    "UNIQUE_HPI_HITS_CSV = HPI_OUTPUTS+\"Unique_HPI_hits.csv\"\n",
    "RESULTS_CLUSTERS = HPI_OUTPUTS+\"results_clusters\" # pickle file to save clusters hits results (to load run `results = pickle.load(open(RESULTS_CLUSTERS, 'rb'))`)\n",
    "RESULTS_SINGLETONS = HPI_OUTPUTS+\"results_singletons\" # pickle file to save singletons hits results (to load run `results = pickle.load(open(RESULTS_SINGLETONS, 'rb'))`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLAST e-value threshold\n",
    "E_VALUE_THRESH = 0.00000001\n",
    "\n",
    "# Similarity threshold between cluster sequence and gene sequence once aligned\n",
    "SIMILARITY_THRESHOLD = 0.9\n",
    "\n",
    "# Good alignment criteria: no more than max(MAX_GAPS_PROP*total number of characters,MAX_GAPS_ABS) gaps.\n",
    "MAX_GAPS_ABS = 3\n",
    "MAX_GAPS_PROP = 1/300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLETONS_FASTA = SeqIO.to_dict(SeqIO.parse(SINGLETONS_FILE, \"fasta\"))    \n",
    "CLUSTERS_FASTA = SeqIO.to_dict(SeqIO.parse(CLUSTERS_FILE, \"fasta\"))   \n",
    "SEQUENCES_FASTA = dict(SINGLETONS_FASTA, **CLUSTERS_FASTA)\n",
    "HPI_FASTA = SeqIO.to_dict(SeqIO.parse(HPI_FILE, \"fasta\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blast hit class\n",
    "\n",
    "We define a python class to record hits characteristics easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hit:\n",
    "    similarity_threshold = SIMILARITY_THRESHOLD\n",
    "    gene_dict = HPI_FASTA\n",
    "    cluster_dict = SEQUENCES_FASTA\n",
    "    \n",
    "    def __init__(self, gene_name, cluster_name, global_similarity, cluster_similarity, start_gap, end_gap):\n",
    "        self.gene_name = gene_name\n",
    "        self.cluster_name = cluster_name\n",
    "        self.global_similarity = global_similarity\n",
    "        self.cluster_similarity = cluster_similarity\n",
    "        self.start_gap = start_gap\n",
    "        self.end_gap = end_gap\n",
    "        \n",
    "    def get_gene_name(self):\n",
    "        description = self.gene_dict[self.gene_name].description\n",
    "        if(\"[gene=\" in description):\n",
    "            return description.split(\"[gene=\")[1].split(\"]\")[0]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    def get_gene_length(self):\n",
    "        return len(Seq((str(self.gene_dict[self.gene_name].seq))))\n",
    "    \n",
    "    def get_cluster_length(self):\n",
    "        return len(Seq((str(self.cluster_dict[self.cluster_name].seq))))\n",
    "\n",
    "    def is_similar(self):\n",
    "        return self.global_similarity > self.similarity_threshold\n",
    "    \n",
    "    def is_fragment(self):\n",
    "        return self.get_cluster_length()<=0.9*self.get_gene_length() and self.cluster_similarity > self.similarity_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing BLAST results\n",
    "\n",
    "### Clusters hits\n",
    "\n",
    "For each BLAST hit of HPI against the Clusters database we align both sequences and we measure the similarity between both sequences and record it as a Hit object in a dictionnary indexed by HPI gene names. We store the results as a pickle object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_handle = open(BLAST_HPI_CLUSTERS)\n",
    "blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "muscle_cline = MuscleCommandline(input=\"algnt_temp.fasta\", out=\"algnt_temp.txt\")\n",
    "results = dict()\n",
    "\n",
    "for blast_record in blast_records:\n",
    "    query = blast_record.query\n",
    "    algnt = dict()\n",
    "    refname = query.split(' ')[0]\n",
    "    results[refname] = []\n",
    "    for alignment in blast_record.alignments:\n",
    "        for hsp in alignment.hsps: \n",
    "            if hsp.expect < E_VALUE_THRESH:\n",
    "                algnt[alignment.title.split(' ')[1]] = CLUSTERS_FASTA[alignment.title.split(' ')[1]]\n",
    "    if(len(algnt.keys())>0):\n",
    "        L = list(algnt.values())\n",
    "        for i in range(len(L)):\n",
    "            SeqIO.write([HPI_FASTA[refname]] + [L[i]],\"algnt_temp.fasta\",\"fasta\") \n",
    "            muscle_cline()\n",
    "            align = AlignIO.read(\"algnt_temp.txt\", \"fasta\")\n",
    "            refindex = 0\n",
    "            hitindex = 1\n",
    "            if(align[1,:].name==refname):\n",
    "                refindex = 1\n",
    "                hitindex = 0\n",
    "            refseq = str(align[refindex,:].seq)\n",
    "            hitseq = str(align[hitindex,:].seq)\n",
    "            lref = len(refseq)\n",
    "            global_sim = 0\n",
    "            cluster_sim = 0\n",
    "            start_gap = (hitseq[0]==\"-\")\n",
    "            end_gap = (hitseq[-1]==\"-\")\n",
    "            gaps = [hitseq[i]==\"-\" for i in range(len(hitseq))]\n",
    "            start = gaps.index(False)\n",
    "            end = len(hitseq)-gaps[::-1].index(False)\n",
    "            for i in range(lref):\n",
    "                if(refseq[i]==hitseq[i]):\n",
    "                    global_sim += 1\n",
    "                    if(i>=start and i<end):\n",
    "                        cluster_sim += 1\n",
    "            hit = Hit(refname, align[hitindex,:].name, global_sim/lref, cluster_sim/(end-start), start_gap, end_gap)\n",
    "            results[refname].append(hit)\n",
    "\n",
    "pickle.dump(results, open(RESULTS_CLUSTERS, 'wb'))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a second dictionnary indexed by cluster names to store the results in a different order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_results = dict()\n",
    "for key in results.keys():\n",
    "    hits = results[key]\n",
    "    for i in range(len(hits)):\n",
    "        if(not hits[i].cluster_name in reverse_results.keys()):\n",
    "            reverse_results[hits[i].cluster_name] = []\n",
    "        reverse_results[hits[i].cluster_name].append(hits[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We output the results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(ANNOTATIONS_CLUSTERS_CSV,\"w\")\n",
    "file.write(\"Cluster,Cluster length,Gene name,Annotation,Gene length,Global similarity,Fragment,Local similarity,Start gap,End gap,Good alignment,Alignment length\\n\")\n",
    "\n",
    "sorted_keys = []\n",
    "for key in reverse_results.keys():\n",
    "    sorted_keys += [int(key[7:])]\n",
    "sorted_keys.sort()\n",
    "for i in range(len(sorted_keys)):\n",
    "    sorted_keys[i] = \"cluster\"+str(sorted_keys[i])\n",
    "    \n",
    "record = SeqIO.to_dict(SeqIO.parse(CLUSTERS_GAPS_FILE, \"fasta\"))\n",
    "total = 0\n",
    "total_good = 0\n",
    "for key in sorted_keys:\n",
    "    hits = reverse_results[key]\n",
    "    sequence = [int(i==\"-\") for i in str(record[key].seq).strip(\"-\")]\n",
    "    a = sequence+[0]\n",
    "    b = [0]+sequence\n",
    "    c = [int((a[i]-b[i])==1) for i in range(len(a))]\n",
    "    gaps = np.sum(np.array(c))\n",
    "    algnt_length = len(str(record[key].seq))\n",
    "    good_alignment = gaps<=max(MAX_GAPS_ABS,MAX_GAPS_PROP*np.sum(1-np.array(sequence)))\n",
    "    total += 1\n",
    "    total_good += int(good_alignment)\n",
    "    for i in range(len(hits)):\n",
    "        if(hits[i].is_similar() or hits[i].is_fragment()):\n",
    "            line = hits[i].cluster_name[7:]+\",\"\n",
    "            line += str(hits[i].get_cluster_length())+\",\"\n",
    "            line += hits[i].get_gene_name()+\",\"\n",
    "            line += HPI_FASTA[hits[i].gene_name].description+\",\"\n",
    "            line += str(hits[i].get_gene_length())+\",\"\n",
    "            line += str(hits[i].global_similarity)+\",\"\n",
    "            line += str(hits[i].is_fragment())+\",\"\n",
    "            line += str(hits[i].cluster_similarity)+\",\"\n",
    "            line += str(hits[i].start_gap)+\",\"\n",
    "            line += str(hits[i].end_gap)+\",\"\n",
    "            line += str(good_alignment)+\",\"\n",
    "            line += str(algnt_length)+\"\\n\"\n",
    "            file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singletons annotations\n",
    "\n",
    "For each BLAST hit of HPI against the Singletons database we align both sequences and we measure the similarity between both sequences and record it as a Hit object in a dictionnary indexed by HPI gene names. We store the results as a pickle object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_handle = open(BLAST_HPI_SINGLETONS)\n",
    "blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "muscle_cline = MuscleCommandline(input=\"algnt_temp.fasta\", out=\"algnt_temp.txt\")\n",
    "results = dict()\n",
    "\n",
    "for blast_record in blast_records:\n",
    "    query = blast_record.query\n",
    "    algnt = dict()\n",
    "    refname = query.split(' ')[0]\n",
    "    results[refname] = []\n",
    "    for alignment in blast_record.alignments:\n",
    "        for hsp in alignment.hsps: \n",
    "            if hsp.expect < E_VALUE_THRESH:\n",
    "                algnt[alignment.title.split(' ')[1]] = SINGLETONS_FASTA[alignment.title.split(' ')[1]]\n",
    "    if(len(algnt.keys())>0):\n",
    "        L = list(algnt.values())\n",
    "        for i in range(len(L)):\n",
    "            SeqIO.write([HPI_FASTA[refname]] + [L[i]],\"algnt_temp.fasta\",\"fasta\") \n",
    "            muscle_cline()\n",
    "            align = AlignIO.read(\"algnt_temp.txt\", \"fasta\")\n",
    "            refindex = 0\n",
    "            hitindex = 1\n",
    "            if(align[1,:].name==refname):\n",
    "                refindex = 1\n",
    "                hitindex = 0\n",
    "            refseq = str(align[refindex,:].seq)\n",
    "            hitseq = str(align[hitindex,:].seq)\n",
    "            lref = len(refseq)\n",
    "            global_sim = 0\n",
    "            cluster_sim = 0\n",
    "            start_gap = (hitseq[0]==\"-\")\n",
    "            end_gap = (hitseq[-1]==\"-\")\n",
    "            gaps = [hitseq[i]==\"-\" for i in range(len(hitseq))]\n",
    "            start = gaps.index(False)\n",
    "            end = len(hitseq)-gaps[::-1].index(False)\n",
    "            for i in range(lref):\n",
    "                if(refseq[i]==hitseq[i]):\n",
    "                    global_sim += 1\n",
    "                    if(i>=start and i<end):\n",
    "                        cluster_sim += 1\n",
    "            hit = Hit(refname, align[hitindex,:].name, global_sim/lref, cluster_sim/(end-start), start_gap, end_gap)\n",
    "            results[refname].append(hit)\n",
    "pickle.dump(results, open(RESULTS_SINGLETONS, 'wb'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a second dictionnary indexed by cluster names to store the results in a different order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_results = dict()\n",
    "for key in results.keys():\n",
    "    hits = results[key]\n",
    "    for i in range(len(hits)):\n",
    "        if(not hits[i].cluster_name in reverse_results.keys()):\n",
    "            reverse_results[hits[i].cluster_name] = []\n",
    "        reverse_results[hits[i].cluster_name].append(hits[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We output the results as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(ANNOTATIONS_SINGLETONS_CSV,\"w\")\n",
    "file.write(\"Cluster,Cluster length,Gene name,Annotation,Gene length,Global similarity,Fragment,Local similarity,Start gap,End gap\\n\")\n",
    "\n",
    "sorted_keys = []\n",
    "for key in reverse_results.keys():\n",
    "    sorted_keys += [int(key[7:])]\n",
    "sorted_keys.sort()\n",
    "for i in range(len(sorted_keys)):\n",
    "    sorted_keys[i] = \"cluster\"+str(sorted_keys[i])\n",
    "    \n",
    "for key in sorted_keys:\n",
    "    hits = reverse_results[key]\n",
    "    for i in range(len(hits)):\n",
    "        if(hits[i].is_similar() or hits[i].is_fragment()):\n",
    "            line = hits[i].cluster_name[7:]+\",\"\n",
    "            line += str(hits[i].get_cluster_length())+\",\"\n",
    "            line += hits[i].get_gene_name()+\",\"\n",
    "            line += K12_FASTA[hits[i].gene_name].description+\",\"\n",
    "            line += str(hits[i].get_gene_length())+\",\"\n",
    "            line += str(hits[i].global_similarity)+\",\"\n",
    "            line += str(hits[i].is_fragment())+\",\"\n",
    "            line += str(hits[i].cluster_similarity)+\",\"\n",
    "            line += str(hits[i].start_gap)+\",\"\n",
    "            line += str(hits[i].end_gap)+\"\\n\"\n",
    "            file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the results\n",
    "\n",
    "Here we merge the results of HPI BLASTs against Clusters and Singletons databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clusters = pickle.load(open(RESULTS_CLUSTERS, 'rb'))\n",
    "results_singletons = pickle.load(open(RESULTS_SINGLETONS, 'rb'))\n",
    "results = dict()\n",
    "\n",
    "for key in results_clusters.keys():\n",
    "    results[key] = results_clusters[key]\n",
    "\n",
    "for key in results_singletons.keys():\n",
    "    if(key not in results.keys()):\n",
    "        results[key] = results_singletons[key]\n",
    "    else:\n",
    "        results[key] += results_singletons[key]\n",
    "\n",
    "file = open(ANNOTATIONS_HPI_CSV,\"w\")\n",
    "file.write(\"Gene name,Annotation,Gene length,Cluster,Cluster length,Global similarity,Fragment,Local similarity,Start gap,End gap\\n\")\n",
    "\n",
    "for key in results.keys():\n",
    "    hits = results[key]\n",
    "    for i in range(len(hits)):\n",
    "        if(hits[i].is_similar() or hits[i].is_fragment()):\n",
    "            line = hits[i].get_gene_name()+\",\"\n",
    "            line += HPI_FASTA[hits[i].gene_name].description+\",\"\n",
    "            line += str(hits[i].get_gene_length())+\",\"\n",
    "            line += hits[i].cluster_name[7:]+\",\"\n",
    "            line += str(hits[i].get_cluster_length())+\",\"\n",
    "            line += str(hits[i].global_similarity)+\",\"\n",
    "            line += str(hits[i].is_fragment())+\",\"\n",
    "            line += str(hits[i].cluster_similarity)+\",\"\n",
    "            line += str(hits[i].start_gap)+\",\"\n",
    "            line += str(hits[i].end_gap)+\"\\n\"\n",
    "            file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additionnal stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clusters = pickle.load(open(RESULTS_CLUSTERS, 'rb'))\n",
    "results_singletons = pickle.load(open(RESULTS_SINGLETONS, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_results_singletons = dict()\n",
    "for key in results_singletons.keys():\n",
    "    hits = results_singletons[key]\n",
    "    for i in range(len(hits)):\n",
    "        if(hits[i].is_similar() or hits[i].is_fragment()):\n",
    "            if(not hits[i].cluster_name in reverse_results_singletons.keys()):\n",
    "                reverse_results_singletons[hits[i].cluster_name] = []\n",
    "            reverse_results_singletons[hits[i].cluster_name].append(hits[i])\n",
    "\n",
    "reverse_results_clusters = dict()\n",
    "for key in results_clusters.keys():\n",
    "    hits = results_clusters[key]\n",
    "    for i in range(len(hits)):\n",
    "        if(hits[i].is_similar() or hits[i].is_fragment()):\n",
    "            if(not hits[i].cluster_name in reverse_results_clusters.keys()):\n",
    "                reverse_results_clusters[hits[i].cluster_name] = []\n",
    "            reverse_results_clusters[hits[i].cluster_name].append(hits[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id = []\n",
    "cluster_id = []\n",
    "gene_length = []\n",
    "fragment = []\n",
    "singleton = []\n",
    "bad_algnt = []\n",
    "gaps = []\n",
    "dashes = []\n",
    "\n",
    "for key in reverse_results_singletons.keys():\n",
    "    hits = reverse_results_singletons[key]\n",
    "    if(len(hits)==1):\n",
    "        gene_id.append(hits[0].gene_name.split(\"gene_\")[1])\n",
    "        cluster_id.append(hits[0].cluster_name[7:])\n",
    "        gene_length.append(hits[0].get_gene_length())\n",
    "        fragment.append(hits[0].is_fragment())\n",
    "        singleton.append(\"True\")\n",
    "        bad_algnt.append(\"\")\n",
    "        gaps.append(\"\")\n",
    "        dashes.append(\"\")\n",
    "\n",
    "for key in reverse_results_clusters.keys():\n",
    "    hits = reverse_results_clusters[key]\n",
    "    if(len(hits)==1):\n",
    "        gene_id.append(hits[0].gene_name)\n",
    "        cluster_id.append(hits[0].cluster_name[7:])\n",
    "        gene_length.append(str(hits[0].get_gene_length()))\n",
    "        fragment.append(str(hits[0].is_fragment()))\n",
    "        singleton.append(\"False\")\n",
    "        sequence = [int(i==\"-\") for i in str(CLUSTERS_FASTA[hits[0].cluster_name].seq)]\n",
    "        a = sequence+[0]\n",
    "        b = [0]+sequence\n",
    "        c = [int((a[i]-b[i])==1) for i in range(len(a))]\n",
    "        gaps_count = np.sum(np.array(c))\n",
    "        characters = len(sequence)-np.sum(np.array(sequence))\n",
    "        if(gaps_count>max(MAX_GAPS_PROP*characters,MAX_GAPS_ABS)):\n",
    "            bad_algnt.append(\"True\")\n",
    "            gaps.append(str(gaps_count))\n",
    "            dashes.append(str(np.sum(np.array(sequence))))\n",
    "        else:\n",
    "            bad_algnt.append(\"False\")\n",
    "            gaps.append(\"\")\n",
    "            dashes.append(\"\")\n",
    "        \n",
    "df = pd.DataFrame({\n",
    "    \"gene_id\":gene_id,\n",
    "    \"cluster_id\":cluster_id,\n",
    "    \"gene_length\":gene_length,\n",
    "    \"fragment\":fragment,\n",
    "    \"singleton\":singleton,\n",
    "    \"bad_algnt\":bad_algnt,\n",
    "    \"gaps\":gaps,\n",
    "    \"dashes\":dashes\n",
    "})\n",
    "     \n",
    "df.to_csv(UNIQUE_HPI_HITS_CSV,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
